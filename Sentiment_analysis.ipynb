{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This work is made in a benefit from a tutorial:\n",
    "https://www.kaggle.com/joelowj/a-sentiment-analysis-tutorial/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datas\n",
    "data = pd.read_csv(\"/home/emremrah/Desktop/DataMin/twitter-sentiment/sample-train-test.csv\",\n",
    "                   encoding='latin-1')\n",
    "data_train = pd.read_csv(\"/home/emremrah/Desktop/DataMin/twitter-sentiment/train.csv\",\n",
    "                        encoding='latin-1')\n",
    "data_test = pd.read_csv(\"/home/emremrah/Desktop/DataMin/twitter-sentiment/test.csv\",\n",
    "                       encoding='latin-1')\n",
    "\n",
    "# Shuffle all of datas\n",
    "data = shuffle(data, random_state=144)\n",
    "data_train = shuffle(data_train, random_state=144)\n",
    "data_test = shuffle(data_test, random_state=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82984</th>\n",
       "      <td>1</td>\n",
       "      <td>@AshNair  OMGGGG Ash Nair. IM A BIG FAN OF YOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98698</th>\n",
       "      <td>1</td>\n",
       "      <td>@CottonCandyKiss yay, i've added her! She is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64272</th>\n",
       "      <td>1</td>\n",
       "      <td>@BinkleyOnStyle 55+ - No Problem! My battle ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>1</td>\n",
       "      <td>#myweakness - my phoneeeee  without it, i'd be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63001</th>\n",
       "      <td>1</td>\n",
       "      <td>@billyraycyrus http://twitpic.com/6p0vb - gorg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment                                      SentimentText\n",
       "82984          1  @AshNair  OMGGGG Ash Nair. IM A BIG FAN OF YOU...\n",
       "98698          1  @CottonCandyKiss yay, i've added her! She is s...\n",
       "64272          1  @BinkleyOnStyle 55+ - No Problem! My battle ax...\n",
       "6788           1  #myweakness - my phoneeeee  without it, i'd be...\n",
       "63001          1  @billyraycyrus http://twitpic.com/6p0vb - gorg..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='ItemID')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    try:\n",
    "        text = re.sub(r'@[A-Za-z0-9_]+', '', text) # remove @ mentions fron tweets\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        text = re.sub('<[^>]*>', ' ', text)    # removes HTML from tweets\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        text = re.sub('(http|https)://[^ ]+ ', '', text)    # removes all the hyperlinks\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        text = re.sub('\\s\\s+', '', text)    # removes all the extra whitespaces\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P|[^T_T])', text)    #find all emoticons\n",
    "    except:\n",
    "        text = text\n",
    "    try:\n",
    "        text = re.sub('[\\W]+', ' ', text.lower()) + ''.join(emoticons).replace('-', '')  # appends emmoticons at the end.\n",
    "    except:\n",
    "        text = text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean tweets from hyperlinks, '@' ect.\n",
    "\n",
    "def clean_tweets (df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82984</th>\n",
       "      <td>1</td>\n",
       "      <td>omgggg ash nair im a big fan of you you daym h...</td>\n",
       "      <td>[omgggg, ash, nair, im, a, big, fan, of, you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98698</th>\n",
       "      <td>1</td>\n",
       "      <td>yay i ve added her she is so damn hearty lt 3  3</td>\n",
       "      <td>[yay, i, ve, added, her, she, is, so, damn, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64272</th>\n",
       "      <td>1</td>\n",
       "      <td>55 no problem my battle axe is a boomer older...</td>\n",
       "      <td>[55, no, problem, my, battle, axe, is, a, boom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>1</td>\n",
       "      <td>myweakness my phoneeeeewithout it i d be d e ...</td>\n",
       "      <td>[myweakness, my, phoneeeeewithout, it, i, d, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63001</th>\n",
       "      <td>1</td>\n",
       "      <td>gorgeous horse</td>\n",
       "      <td>[gorgeous, horse]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment                                      SentimentText  \\\n",
       "82984          1  omgggg ash nair im a big fan of you you daym h...   \n",
       "98698          1   yay i ve added her she is so damn hearty lt 3  3   \n",
       "64272          1   55 no problem my battle axe is a boomer older...   \n",
       "6788           1   myweakness my phoneeeeewithout it i d be d e ...   \n",
       "63001          1                                    gorgeous horse    \n",
       "\n",
       "                                                  Tokens  \n",
       "82984  [omgggg, ash, nair, im, a, big, fan, of, you, ...  \n",
       "98698  [yay, i, ve, added, her, she, is, so, damn, he...  \n",
       "64272  [55, no, problem, my, battle, axe, is, a, boom...  \n",
       "6788   [myweakness, my, phoneeeeewithout, it, i, d, b...  \n",
       "63001                                  [gorgeous, horse]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# First preprocess the texts (tweets), then tokenize them with nltk TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "data['SentimentText'] = data['SentimentText'].apply(preprocess)\n",
    "data = clean_tweets(data, \"SentimentText\")\n",
    "\n",
    "data['Tokens'] = data[\"SentimentText\"].apply(tokenizer.tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 1285766 means total words in all of tweets\n",
      "Vocabulary size: 66817 means number of different words in all tweets\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in data['Tokens'] for word in tokens]\n",
    "vocab = sorted(list(set(all_words)))\n",
    "print(\"Total words: {} means total words in all of tweets\\n\".format(len(all_words)) + \n",
    "      \"Vocabulary size: {} means number of different words in all tweets\".format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer is a bag-of-words representation implemented in scikit-learn\n",
    "# Tfidf explained briefly in 'O'Reilly Introduction  to Machine Learning'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "list_corpus = data['SentimentText'].tolist()\n",
    "list_labels = data['Sentiment'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.15,\n",
    "                                                   random_state=44)\n",
    "\n",
    "vect = CountVectorizer(min_df=2, ngram_range=(1, 3)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg with defaults vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7679\n",
      "Best parameters:  {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "params_grid = {'C': [0.1, 1]}\n",
    "lr_grid = GridSearchCV(LogisticRegression(), params_grid, cv=5)\n",
    "lr_grid.fit(X_train_vectorized, y_train)\n",
    "print(\"Best score: {:.4f}\".format(lr_grid.best_score_))\n",
    "print(\"Best parameters: \", lr_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8500\n",
      "Testing accuracy: 0.7706\n"
     ]
    }
   ],
   "source": [
    "lr_best = LogisticRegression(C=0.1).fit(X_train_vectorized, y_train)\n",
    "print(\"Training accuracy: {:.4f}\".format(lr_best.score(X_train_vectorized, y_train)))\n",
    "print(\"Testing accuracy: {:.4f}\".format(lr_best.score(X_test_vectorized, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default vocabulary settings, Logistic Regression made a presicion around %75 on test set.\n",
    "Now we try to change some parameters, like n-gram range, min-df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With parameters changed, our training score is slightly increased to %76\n",
    "\n",
    "##### With ngram_range=(1, 5), there was over 350k vocabulary size, so over 350k fetures. With ngram_range=(1, 2), there is around 79k, wich is much less and the precision not even reduced. But the computational cost reduced drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And without cross-validation, with best parameters, our training score is 83% and test score is 76%. We have slightly overfitting here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7175 1322]\n",
      " [2119 4383]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "predictions = lr_best.predict(X_test_vectorized)\n",
    "print(confusion_matrix(y_test, predictions, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As seen, our model predicted most of 'negatives' as 'positives'. Also test scenario seems a bit unbalanced since there is  17k of positives and 13k of negatives. Would be better if there is 15k-15k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph for different parameters\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "best_test=0\n",
    "train_score=0\n",
    "best_train=0\n",
    "for max_depth in range(1, 7):\n",
    "    for learning_rate in [1]:\n",
    "        gbm=GradientBoostingClassifier(max_depth=max_depth,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       random_state=44).fit(X_train_counts, y_train)\n",
    "        train_score= gbm.score(X_train_counts, y_train)\n",
    "        train_acc.append(gbm.score(X_train_counts, y_train))\n",
    "        test_acc.append(gbm.score(X_test_counts, y_test))\n",
    "        if train_score > best_train:\n",
    "            best_train=train_score\n",
    "            best_test=gbm.score(X_test_counts, y_test)\n",
    "            best_parameters = {'max_depth': max_depth, 'learning_rate': learning_rate}\n",
    "\n",
    "print(\"Best train score: {:.5f}\".format(best_train))\n",
    "print(\"Best test score: {:.5f}\".format(best_test))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "plt.plot(range(1, 7), train_acc, label=\"TRAIN\")\n",
    "plt.plot(range(1, 7), test_acc, label=\"TEST\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"iterasyon\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
